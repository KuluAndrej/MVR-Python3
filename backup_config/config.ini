# backup of the config file responsible for good classification of different structures gathered from learning
# on fixed segment of ts

[data_extraction]
dataset_filename 	 = /data/data_to_fit.txt
init_models_filename = /data/init_models.txt

[flag_type_of_processing]
# variants: 'fit_data', 'time_series_processing', 'fit_and_collect'
flag = time_series_processing


[model_generation]
# the number of crossings among the population on a iteration
crossing_number 	 = 30
# the number of mutations among the population on a iteration
mutation_number 	 = 30
# the number of random generated models on a iteration
random_models_number = 100
# structural complexity of random models generated
random_models_complexity = 30
# the number of best models from a generated population to pass to the next iteration
best_models_number	 = 45
# flag signifying if the parameters of superpositions will be tuned
# if 'False' is set, then all parameters (if presented) are set to 1
is_parametric = True
# type of superpositions selection
# variants: [MSE, Error_structural]
type_selection       = Error_structural
# penalty on excessive structural complexity (number of tokens in superposition)
# if a model has MSE equal to 'x' and structural complexity equal to 'y', then the additive penalty is 'xy'
# -- the best for fitting models to data is 0.00002
structural_penalty   = 0.0001
# specifies maximum number of parameters
maximum_param_number = 20
# specifies maximum structural complexity of a model
maximum_complexity 	 = 40
# for better convergence we start generation with big bunch () of random models
number_of_init_random_models = 10000
size_init_random_models		 = 13
# if the flag is set to 'False', we do not load bunch of random init models
do_init_random_generation = False


[accuracy_requirement]
# maximum number of performed cycles (evolutions)
max_number_cycle_count = 10
# required accuracy; when it is reached, evolutions are stopped
required_accuracy = 0.001

[time_series_processing]
# set of labels of ts to classify
# labels = chest_volume, heart_rate, oxygen_concentration
labels = chest_volume, heart_rate, oxygen_concentration
# locations of the ts
root_path = /ts_processing/
# extension of files containing data about ts
extension = .txt
# folder for output files
where_to_store_models = populations/collected_models3/
# specifies number of segments for ts to be split on
number_of_segments = 50


[stagnation]
# if MSE changes very slow (< threshhold_of_slow_mse_change) for the last 'window_size' iterations ...
# ... starting from 'init_iteration', we break the generation
lowest_possible_rate = 0.01
window_size    = 100
init_iteration = 200

[fit_and_collect]
# folder for output files
where_to_store_models = populations/first_segments2/
# extension of files containing data about ts
extension = .txt
# number of times of fitting
number_fittings = 50